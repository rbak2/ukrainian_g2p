{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QNM4afoyKgB8",
        "outputId": "58892dd5-3671-4bdc-85ea-e78aaf4f1df7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tokenize-uk in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from tokenize-uk) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tokenize-uk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import phonemizer_test as phonemizer\n",
        "import re\n",
        "\n",
        "phonemized = []\n",
        "dict_rules = {r\"[^ а-яієїІґ́’'\\+]\": \"clean\",\n",
        "            r\"\\+\": \"stress\",\n",
        "            \"щ\": \"shch\",\n",
        "            \"ь\": \"soft_sign\",\n",
        "            \"['’]\": \"apostrophe\",\n",
        "            \"дз\": \"dz\",\n",
        "            \"дж\": \"dzh\",\n",
        "            \"я\": \"ja\",\n",
        "            \"ю\": \"ju\",\n",
        "            \"є\": \"je\",\n",
        "            \"ї\": \"ji\",\n",
        "            \"(?<=[дзлнрстцq])j\": \"j_palatal\",\n",
        "            \"(?<=[бвгжкмпфхчшґs])j\": \"j_half_palatal\",\n",
        "            \"й\": \"y\",\n",
        "            \"(?<=[дзлнрстцq])і\": \"i_palatal\",\n",
        "            \"f\": \"apostrophe\",\n",
        "            \"т´с(?=´а)\": \"tsia\",\n",
        "            \"(?<=с)ц(?=´ц)\": \"ststs_cluster\",\n",
        "            \"(?<=д)[шч](?=с)\": \"dshs_cluster\",\n",
        "            \"ст(?=с´к)\": \"stsk_cluster\",\n",
        "            \"(?<=[сшн])т(?=[чцдс])\": \"t_clusters\",\n",
        "            \"тс(?=´к|тв)\": \"ts_clusters\",\n",
        "            \"(?<=с)т(?=н)\": \"stn_cluster\",\n",
        "            r\"(?:(?<=на|[вп]і)|(?<=[сп]ере))(́?)q\": \"dz_boundary\",\n",
        "            r\"(?:(?<=\\sна|\\sві)|(?<=пі|^на|^ві)|(?<=\\sпере)|(?<=^пере))(́?)s\": \"dzh_boundary\",\n",
        "            r\"(?:(?<=\\s)|(?<=^))з(?=[сцчш])\": \"s_boundary\",\n",
        "            r\"(?:(?<=\\s)|(?<=^))з(?=[кптфх])\": \"s_boundary_word\",\n",
        "            \"п(?=[бдзжгґqs])\": \"p_voiced\",\n",
        "            \"к(?=[бдзжгґqs])\": \"k_voiced\",\n",
        "            \"х(?=[бдзжгґqs])\": \"kh_voiced\",\n",
        "            \"т(?=´?[бдзжгґqs])\": \"d_voiced\",\n",
        "            \"с(?=´?[бдзжгґqs])\": \"z_voiced\",\n",
        "            \"ш(?=[бдзжгґqs])\": \"zh_voiced\",\n",
        "            \"ц(?=´?[бдзжгґqs])\": \"ts_voiced\",\n",
        "            \"ч(?=[бдзжгґqs])\": \"ch_voiced\",\n",
        "            \"[дs](?=´?[цзсq])\": \"D_hissing\",\n",
        "            \"[тч](?=´?[цзсq])\": \"T_hissing\",\n",
        "            \"[дq]´?(?=[чжшs])\": \"D_hushing\",\n",
        "            \"[тц]´?(?=[чжшs])\": \"T_hushing\",\n",
        "            \"з´?(?=[чжшs])\": \"z_assimilation\",\n",
        "            \"с´?(?=[чжшs])\": \"s_assimilation\",\n",
        "            \"ж(?=[зсцq])\": \"zh_assimilation\",\n",
        "            \"ш(?=[зсцq])\": \"sh_assimilation\",\n",
        "            r\"(?:(?<=н´і|д´[оі])|(?<=во|[лд]е|кі))(́?)г(?=[кт])\": \"h_voiceless\",\n",
        "            \"(?<=[дтнзсцлq])(?=[дтнзсцлq]´)\": \"palatalization\",\n",
        "            \"(?<![бвгґжкпфхчшдзлрстцмнqsj'´])в(?!['аоеуіи])\": \"w_vocalization\",\n",
        "            \"ф(?=[бдзжгґqs])\": \"f_voiced\",\n",
        "            \"(?<=[бвгжкмпфхчшґs])і\": \"i_half_palatal\",\n",
        "            r\"([бвгґжкпфхчшрмs])\\1'\": \"geminated_half\",\n",
        "            r\"рр´\": \"geminated_r\",\n",
        "            \"q\": \"dz\",\n",
        "            \"s\": \"dzh\",\n",
        "            \"д͡з\": \"dz\",\n",
        "            \"д͡ж\": \"dzh\",\n",
        "            \"j(?![аоеуіи])\": \"j_vocalization\",\n",
        "            \"(?<=[мн][аеиоу])|(?<=м'[аеіуо])|(?<=н´[аеоуі])\": \"nasalization_p\",\n",
        "            \"(?<=[j´'])(?=[аеоу])\": \"i_articulation_p\",\n",
        "            \"(?<=[бвгґжкпфхчшдзлрстцмнqsj'´])(?=·?[оу])\": \"labialization\",\n",
        "            r\"(?<=[иіаеоу])(?=[мн])\": \"nasalization_r\",\n",
        "            r\"(?:(?<=[аеоу])|(?<=[аеоу]̃))(?=[дзлрстцнq]´|j|[бвгжкмпфхчшґs]')\": \"i_articulation_r\",\n",
        "            r\"(?<=[иіаеоу])́(?=[мн])\": \"nasalization_r_stress\",\n",
        "            r\"(?:(?<=[аеоу]́)|(?<=[аеоу]̃́))(?=[дзлрстцнq]´|j|[бвгжкмпфхчшґs]')\": \"i_articulation_r_stress\",\n",
        "            r\"([бвгґжкпфхчшдзлрстцмнqs]´?)\\1(['´]?°?)\": \"geminated_all\",\n",
        "            r\"(?<=·е)(̃?)(?=·)\": \"e_to_i\",\n",
        "            r\"(е̃?)(?!́|̃́|\\(|\\))\": \"e_to_y\",\n",
        "            r\"(и̃?)(?!́|̃́|\\(|\\))\": \"y_to_e\",\n",
        "            r\"(?<=о)(̃?)(?=[бвгґжкпфхчшдзлрстцмнqsўjĭ͡'´°·:]+[у]̃?́)\": \"o_to_u\",\n",
        "            r\"\\(и\\)(?=(·в'і|м|·j°·у)?(\\s|$))\": \"e_affix\",\n",
        "            r\"\\(і\\)(?=(·в'і|·j°·у)(\\s|$))\": \"e_affix_i\",\n",
        "            r\"\\(е\\)(?=(х|ĭ|м|ш|т´)?(\\s|$))\": \"y_affix\",\n",
        "            r\"(?:(?<=\\sе)|(?<=^е))\\(и\\)\": \"e_start\",\n",
        "            r\"(?:(?<=\\sи)|(?<=^и))\\(е\\)\": \"y_start\"}\n",
        "\n",
        "\n",
        "with open(f\"words_spell.txt\", \"r\") as f:\n",
        "        file = f.read()\n",
        "list_of_words = file.split(\"\\n\")\n",
        "\n",
        "\n",
        "with open(f\"Transcription.csv\", \"w\", newline=\"\") as csvfile:\n",
        "    file_writer = csv.writer(csvfile, delimiter=',')\n",
        "    file_writer.writerow([\"Word\", \"Broad transcription\", \"Broad rules\", \"Narrow transcription\", \"Narrow rules\", \"IPA transcription\", \"IPA rules\", \"Comment\"])\n",
        "    for word in list_of_words:\n",
        "        output_word = phonemizer.remove_punctuation(word)\n",
        "        output_word = phonemizer.Transcriptor(output_word).transcribe_baseline()\n",
        "\n",
        "        #print(output_word)\n",
        "\n",
        "        rules_broad = []\n",
        "        word_to_match = re.sub(r\"[а-яіїєґ’']\", \"\", word)\n",
        "        if word[:3].isupper() and re.match(r\"\\b[АЕОИУІЇЮЯЄ]?[БВГҐДЖЗПТЦЧЛМНРСФКХШЩЙ]{2,}[АЕОИУІЇЮЯЄ]?\\b\", word_to_match):\n",
        "            rules_broad.append(\"abbreviation\")\n",
        "        for rule in output_word[1]:\n",
        "            rules_broad.append(dict_rules[rule])\n",
        "        rules_narrow = []\n",
        "        for rule in output_word[3]:\n",
        "            rules_narrow.append(dict_rules[rule])\n",
        "        rules_ipa = []\n",
        "        for rule in output_word[5]:\n",
        "            rules_ipa.append(dict_rules[rule])\n",
        "\n",
        "        file_writer.writerow([word, output_word[0], list(set(rules_broad)), output_word[2], list(set(rules_narrow)), output_word[4], list(set(rules_ipa)), \"\"])"
      ],
      "metadata": {
        "id": "fZKcUgou7_LH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "import re\n",
        "dict_rules = {r\"[^ а-яієїІґ́’'\\+]\": \"clean\",\n",
        "            r\"\\+\": \"stress\",\n",
        "            \"щ\": \"shch\",\n",
        "            \"ь\": \"soft_sign\",\n",
        "            \"['’]\": \"apostrophe\",\n",
        "            \"дз\": \"dz\",\n",
        "            \"дж\": \"dzh\",\n",
        "            \"я\": \"ja\",\n",
        "            \"ю\": \"ju\",\n",
        "            \"є\": \"je\",\n",
        "            \"ї\": \"ji\",\n",
        "            \"(?<=[дзлнрстцq])j\": \"j_palatal\",\n",
        "            \"(?<=[бвгжкмпфхчшґs])j\": \"j_half_palatal\",\n",
        "            \"й\": \"y\",\n",
        "            \"(?<=[дзлнрстцq])і\": \"i_palatal\",\n",
        "            \"f\": \"apostrophe\",\n",
        "            \"т´с(?=´а)\": \"tsia\",\n",
        "            \"(?<=с)ц(?=´ц)\": \"ststs_cluster\",\n",
        "            \"(?<=д)[шч](?=с)\": \"dshs_cluster\",\n",
        "            \"ст(?=с´к)\": \"stsk_cluster\",\n",
        "            \"(?<=[сшн])т(?=[чцдс])\": \"t_clusters\",\n",
        "            \"тс(?=´к|тв)\": \"ts_clusters\",\n",
        "            \"(?<=с)т(?=н)\": \"stn_cluster\",\n",
        "            r\"(?:(?<=на|[вп]і)|(?<=[сп]ере))(́?)q\": \"dz_boundary\",\n",
        "            r\"(?:(?<=\\sна|\\sві)|(?<=пі|^на|^ві)|(?<=\\sпере)|(?<=^пере))(́?)s\": \"dzh_boundary\",\n",
        "            r\"(?:(?<=\\s)|(?<=^))з(?=[сцчш])\": \"s_boundary\",\n",
        "            r\"(?:(?<=\\s)|(?<=^))з(?=[кптфх])\": \"s_boundary_word\",\n",
        "            \"п(?=[бдзжгґqs])\": \"p_voiced\",\n",
        "            \"к(?=[бдзжгґqs])\": \"k_voiced\",\n",
        "            \"х(?=[бдзжгґqs])\": \"kh_voiced\",\n",
        "            \"т(?=´?[бдзжгґqs])\": \"d_voiced\",\n",
        "            \"с(?=´?[бдзжгґqs])\": \"z_voiced\",\n",
        "            \"ш(?=[бдзжгґqs])\": \"zh_voiced\",\n",
        "            \"ц(?=´?[бдзжгґqs])\": \"ts_voiced\",\n",
        "            \"ч(?=[бдзжгґqs])\": \"ch_voiced\",\n",
        "            \"[дs](?=´?[цзсq])\": \"D_hissing\",\n",
        "            \"[тч](?=´?[цзсq])\": \"T_hissing\",\n",
        "            \"[дq]´?(?=[чжшs])\": \"D_hushing\",\n",
        "            \"[тц]´?(?=[чжшs])\": \"T_hushing\",\n",
        "            \"з´?(?=[чжшs])\": \"z_assimilation\",\n",
        "            \"с´?(?=[чжшs])\": \"s_assimilation\",\n",
        "            \"ж(?=[зсцq])\": \"zh_assimilation\",\n",
        "            \"ш(?=[зсцq])\": \"sh_assimilation\",\n",
        "            r\"(?:(?<=н´і|д´[оі])|(?<=во|[лд]е|кі))(́?)г(?=[кт])\": \"h_voiceless\",\n",
        "            \"(?<=[дтнзсцлq])(?=[дтнзсцлq]´)\": \"palatalization\",\n",
        "            \"abbr\": \"abbreviation\"}\n",
        "\n",
        "dict_rules_n = {\n",
        "            \"д͡з\": \"dz\",\n",
        "            \"д͡ж\": \"dzh\",\n",
        "            \"(?<![бвгґжкпфхчшдзлрстцмнqsj'´])в(?!['аоеуіи])\": \"w_vocalization\",\n",
        "            \"ф(?=[бдзжгґqs])\": \"f_voiced\",\n",
        "            \"(?<=[бвгжкмпфхчшґs])і\": \"i_half_palatal\",\n",
        "            \"j(?![аоеуіи])\": \"j_vocalization\",\n",
        "            \"(?<=[мн][аеиоу])|(?<=м'[аеіуо])|(?<=н´[аеоуі])\": \"nasalization_p\",\n",
        "            \"(?<=[j´'])(?=[аеоу])\": \"i_articulation_p\",\n",
        "            \"(?<=[бвгґжкпфхчшдзлрстцмнqsj'´])(?=·?[оу])\": \"labialization\",\n",
        "            r\"(?<=[иіаеоу])(?=[мн])\": \"nasalization_r\",\n",
        "            r\"(?:(?<=[аеоу])|(?<=[аеоу]̃))(?=[дзлрстцнq]´|j|[бвгжкмпфхчшґs]')\": \"i_articulation_r\",\n",
        "            r\"(?<=[иіаеоу])́(?=[мн])\": \"nasalization_r_stress\",\n",
        "            r\"(?:(?<=[аеоу]́)|(?<=[аеоу]̃́))(?=[дзлрстцнq]´|j|[бвгжкмпфхчшґs]')\": \"i_articulation_r_stress\",\n",
        "            r\"([бвгґжкпфхчшдзлрстцмнqs]´?)\\1(['´]?°?)\": \"geminated_all\"}\n",
        "\n",
        "dict_rules_ipa = {\"(?<![бвгґжкпфхчшдзлрстцмнqsj'´])в(?!['аоеуіи])\": \"w_vocalization\",\n",
        "            \"ф(?=[бдзжгґqs])\": \"f_voiced\",\n",
        "            \"(?<=[бвгжкмпфхчшґs])і\": \"i_half_palatal\",\n",
        "            r\"([бвгґжкпфхчшрмs])\\1'\": \"geminated_half\",\n",
        "            r\"рр´\": \"geminated_r\",\n",
        "            \"q\": \"dz\",\n",
        "            \"s\": \"dzh\"}\n",
        "\n",
        "def create_table(t_row, r_row, dict_r):\n",
        "    for value in set(dict_r.values()):\n",
        "        with open(f\"results/Transcription_{value}.csv\", \"w\", newline=\"\") as csvfile:\n",
        "            file_writer = csv.writer(csvfile, delimiter=',')\n",
        "            file_writer.writerow([\"Word\", \"Transcription\", \"Rules\", \"Comment\"])\n",
        "\n",
        "            for row in list(file):\n",
        "                if value in row[r_row]:\n",
        "                    file_writer.writerow(row)\n",
        "\n",
        "\n",
        "with open(f\"Transcription.csv\", \"r\") as f:\n",
        "    file = list(csv.reader(f))[1:]\n",
        "    create_table(1, 2, dict_rules)\n",
        "    create_table(3, 4, dict_rules_n)\n",
        "    create_table(5, 6, dict_rules_ipa)"
      ],
      "metadata": {
        "id": "0m7UxU-ZC8ta"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/results.zip /content/results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MR7jgOI_LHCK",
        "outputId": "201ca156-9e0f-40d6-8aac-706299d4ca4c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/results/ (stored 0%)\n",
            "  adding: content/results/Transcription_D_hushing.csv (deflated 93%)\n",
            "  adding: content/results/Transcription_abbreviation.csv (deflated 84%)\n",
            "  adding: content/results/Transcription_nasalization_r_stress.csv (stored 0%)\n",
            "  adding: content/results/Transcription_geminated_r.csv (deflated 89%)\n",
            "  adding: content/results/Transcription_shch.csv (deflated 93%)\n",
            "  adding: content/results/Transcription_t_clusters.csv (deflated 92%)\n",
            "  adding: content/results/Transcription_D_hissing.csv (deflated 93%)\n",
            "  adding: content/results/Transcription_clean.csv (deflated 92%)\n",
            "  adding: content/results/Transcription_nasalization_p.csv (deflated 92%)\n",
            "  adding: content/results/Transcription_w_vocalization.csv (deflated 92%)\n",
            "  adding: content/results/Transcription_ju.csv (deflated 92%)\n",
            "  adding: content/results/Transcription_i_articulation_r.csv (deflated 92%)\n",
            "  adding: content/results/Transcription_T_hushing.csv (deflated 91%)\n",
            "  adding: content/results/Transcription_dzh.csv (deflated 92%)\n",
            "  adding: content/results/Transcription_labialization.csv (deflated 92%)\n",
            "  adding: content/results/Transcription_h_voiceless.csv (deflated 92%)\n",
            "  adding: content/results/Transcription_i_palatal.csv (deflated 92%)\n",
            "  adding: content/results/Transcription_tsia.csv (deflated 93%)\n",
            "  adding: content/results/Transcription_soft_sign.csv (deflated 92%)\n",
            "  adding: content/results/Transcription_stsk_cluster.csv (deflated 92%)\n",
            "  adding: content/results/Transcription_z_voiced.csv (deflated 91%)\n",
            "  adding: content/results/Transcription_sh_assimilation.csv (deflated 93%)\n",
            "  adding: content/results/Transcription_i_articulation_p.csv (deflated 92%)\n",
            "  adding: content/results/Transcription_dz.csv (deflated 93%)\n",
            "  adding: content/results/Transcription_dshs_cluster.csv (deflated 65%)\n",
            "  adding: content/results/Transcription_dzh_boundary.csv (deflated 93%)\n",
            "  adding: content/results/Transcription_geminated_all.csv (deflated 93%)\n",
            "  adding: content/results/Transcription_T_hissing.csv (deflated 90%)\n",
            "  adding: content/results/Transcription_ts_voiced.csv (deflated 91%)\n",
            "  adding: content/results/Transcription_dz_boundary.csv (deflated 93%)\n",
            "  adding: content/results/Transcription_palatalization.csv (deflated 92%)\n",
            "  adding: content/results/Transcription_j_palatal.csv (deflated 92%)\n",
            "  adding: content/results/Transcription_ji.csv (deflated 90%)\n",
            "  adding: content/results/Transcription_je.csv (deflated 92%)\n",
            "  adding: content/results/Transcription_stn_cluster.csv (deflated 93%)\n",
            "  adding: content/results/Transcription_ja.csv (deflated 93%)\n",
            "  adding: content/results/Transcription_apostrophe.csv (deflated 92%)\n",
            "  adding: content/results/Transcription_ts_clusters.csv (deflated 92%)\n",
            "  adding: content/results/Transcription_j_half_palatal.csv (deflated 92%)\n",
            "  adding: content/results/Transcription_i_half_palatal.csv (deflated 92%)\n",
            "  adding: content/results/Transcription_j_vocalization.csv (deflated 92%)\n",
            "  adding: content/results/Transcription_i_articulation_r_stress.csv (stored 0%)\n",
            "  adding: content/results/Transcription_ch_voiced.csv (deflated 90%)\n",
            "  adding: content/results/Transcription_zh_voiced.csv (deflated 89%)\n",
            "  adding: content/results/Transcription_s_assimilation.csv (deflated 92%)\n",
            "  adding: content/results/Transcription_s_boundary_word.csv (deflated 75%)\n",
            "  adding: content/results/Transcription_p_voiced.csv (deflated 90%)\n",
            "  adding: content/results/Transcription_f_voiced.csv (deflated 90%)\n",
            "  adding: content/results/Transcription_z_assimilation.csv (deflated 92%)\n",
            "  adding: content/results/Transcription_kh_voiced.csv (deflated 90%)\n",
            "  adding: content/results/Transcription_y.csv (deflated 92%)\n",
            "  adding: content/results/Transcription_zh_assimilation.csv (deflated 91%)\n",
            "  adding: content/results/Transcription_geminated_half.csv (deflated 91%)\n",
            "  adding: content/results/Transcription_nasalization_r.csv (deflated 92%)\n",
            "  adding: content/results/Transcription_stress.csv (stored 0%)\n",
            "  adding: content/results/Transcription_ststs_cluster.csv (deflated 89%)\n",
            "  adding: content/results/Transcription_s_boundary.csv (deflated 92%)\n",
            "  adding: content/results/Transcription_k_voiced.csv (deflated 91%)\n",
            "  adding: content/results/Transcription_d_voiced.csv (deflated 92%)\n"
          ]
        }
      ]
    }
  ]
}